rec_mean = output%>%filter(Rec_Season=="rec")%>%group_by(MonitoringLocationIdentifier, CharacteristicName,ResultMeasure.MeasureUnitCode)%>%summarise(rec_ssn_arithmean=mean(DailyResultMeasureValue),rec_ssn_perc_exc = sum(Exceeds)/length(Exceeds)*100)
dat_agg = merge(dat_agg, rec_mean, all = TRUE)
if(aggFun=="gmean"){
dat_agg_geo = output%>%group_by(MonitoringLocationIdentifier, CharacteristicName, ResultMeasure.MeasureUnitCode)%>%summarise(geomean = gmean(DailyResultMeasureValue))
rec_geo = output%>%filter(Rec_Season=="rec")%>%group_by(MonitoringLocationIdentifier, CharacteristicName, ResultMeasure.MeasureUnitCode)%>%summarise(rec_ssn_geomean=gmean(DailyResultMeasureValue))
dat_agg_geo = merge(dat_agg_geo, rec_geo, all = TRUE)
}
dat_agg = merge(dat_agg, dat_agg_geo, all = TRUE)
if("DailyFlowValue"%in%colnames(output)){
flo_agg = output%>%filter(!is.na(DailyFlowValue))%>%group_by(MonitoringLocationIdentifier, ResultMeasure.MeasureUnitCode)%>%summarise(daterange = paste0(min(Date)," to ",max(Date)),samplesize=length(DailyFlowValue),minconc = min(DailyFlowValue),arithmean=mean(DailyFlowValue),maxconc = max(DailyFlowValue))
dat_agg = plyr::rbind.fill(dat_agg, flo_agg)
dat_agg$CharacteristicName[is.na(dat_agg$CharacteristicName)] = "Flow"
}
write.csv(dat_agg, paste0(au_name,"_summary_table_stats.csv"), row.names = FALSE)
head(dat_agg)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none") # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
dat = output
dat = dat[order(dat$Date),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
t = ggplot(dat, aes(Date,DailyResultMeasureValue, fill=as.factor(MonitoringLocationIdentifier)))+scale_x_date(limits=c(min(dat$Date), max(dat$Date)))+geom_point(shape=21,color="#646464", size=2)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=2)+theme_classic()+labs(x="Date", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)
t
ggsave(paste0(au_name,"_timeseries.jpg"),width=6,height=5, units="in", dpi=500)
dat = output
dat$month = lubridate::month(dat$Date, label=TRUE)
dat = dat[order(dat$month),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
g = ggplot(dat, aes(month, DailyResultMeasureValue, fill=factor(MonitoringLocationIdentifier)))+geom_blank()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(DailyResultMeasureValue)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+geom_jitter(position=position_jitter(0), size=3, shape=21, color="#646464", alpha=0.65)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=2)+theme_classic()+labs(x="Month", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=3, shape=23)
g
ggsave(paste0(au_name,"_monthly.jpg"),width=8,height=5, units="in", dpi=500)
if("TMDL"%in%colnames(output)){
ldc=output
ldc_month = subset(ldc, !is.na(ldc$Observed_Loading))
ldc_month = ldc_month%>%select(Date,MonitoringLocationIdentifier,TMDL,Observed_Loading)%>%pivot_longer(cols=c(TMDL,Observed_Loading),names_to="Type",values_to="Loading",values_drop_na=TRUE)
ldc_month$Loading_Giga = ldc_month$Loading/1000000000
ldc_month$month = lubridate::month(ldc_month$Date, label=TRUE, abbr=TRUE)
ldc_month1 = ldc_month%>%group_by(MonitoringLocationIdentifier,Type,month)%>%summarise(mean_Load = mean(Loading_Giga))
ldcsites = unique(ldc_month1$MonitoringLocationIdentifier)
for(i in 1:length(ldcsites)){
name = ldcsites[i]
g = ggplot(ldc_month1, aes(x=month, y=mean_Load, fill=Type))+geom_blank()+theme_classic()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(ldc_month1$mean_Load*1.1)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+labs(x="Month",y="GigaMPN/day")+geom_col(position="dodge", color="#646464")+scale_fill_manual(values=c("#00a1c6","#034963"),name="",breaks=c("Observed_Loading","TMDL"),labels=c("Observed","TMDL"))+guides(color="none")
g
ggsave(paste0(name,"_monthly_load.jpg"),width=8,height=4, units="in", dpi=500)
}
g
}
dat = output
dat$month = lubridate::month(dat$Date, label=TRUE)
dat = dat[order(dat$month),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
g = ggplot(dat, aes(month, DailyResultMeasureValue, fill=factor(MonitoringLocationIdentifier)))+geom_blank()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(DailyResultMeasureValue)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+geom_jitter(position=position_jitter(0), size=3, shape=21, color="#646464", alpha=0.65)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Month", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=3, shape=23)
g
ggsave(paste0(au_name,"_monthly.jpg"),width=8,height=5, units="in", dpi=500)
ggsave(paste0(au_name,"_monthly.jpg"),width=8,height=16, units="in", dpi=500)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none", axis.text.x=element_text(angle=-45, vjust=1, hjust=1)) # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none", axis.text.x=element_text(angle=-45)) # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
View(dat_agg)
unique(dat_agg$MonitoringLocationIdentifier)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none", axis.text.x=element_text(angle=-45, hjust=1)) # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none", axis.text.x=element_text(angle=45, hjust=1)) # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
?facet_wrap
dat = output
dat = dat[order(dat$Date),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
t = ggplot(dat, aes(Date,DailyResultMeasureValue, fill=as.factor(MonitoringLocationIdentifier)))+scale_x_date(limits=c(min(dat$Date), max(dat$Date)))+geom_point(shape=21,color="#646464", size=2)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Date", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)
t
ggsave(paste0(au_name,"_timeseries.jpg"),width=6,height=5, units="in", dpi=500)
dat = output
dat = dat[order(dat$Date),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
t = ggplot(dat, aes(Date,DailyResultMeasureValue, fill=as.factor(MonitoringLocationIdentifier)))+scale_x_date(limits=c(min(dat$Date), max(dat$Date)))+geom_point(shape=21,color="#646464", size=2)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Date", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)
t
ggsave(paste0(au_name,"_timeseries.jpg"),width=6,height=5, units="in", dpi=500)
dat = output
dat$month = lubridate::month(dat$Date, label=TRUE)
dat = dat[order(dat$month),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
g = ggplot(dat, aes(month, DailyResultMeasureValue, fill=factor(MonitoringLocationIdentifier)))+geom_blank()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(DailyResultMeasureValue)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+geom_jitter(position=position_jitter(0), size=3, shape=21, color="#646464", alpha=0.65)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Month", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=3, shape=23)
g
ggsave(paste0(au_name,"_monthly.jpg"),width=8,height=5, units="in", dpi=500)
read.csv("em_creek.csv")
setwd("C:\\Users\\ehinman\\Desktop\\emigration")
read.csv("em_creek.csv")
dat = read.csv("em_creek.csv")
flow1 = readxl::read_xlsx("Em Cyn Flow Data.xlsx", sheet=1)
View(flow1)
flow2 = readxl::read_xlsx("Em Cyn Flow Data.xlsx", sheet=2)
flow3 = readxl::read_xlsx("Em Cyn Flow Data.xlsx", sheet=3)
flow1 = readxl::read_xlsx("Em Cyn Flow Data.xlsx", sheet=1)[,c(1:5)]
View(flow1)
View(flow2)
View(flow3)
flow = plyr::rbind.fill(flow1, flow2, flow3)
str(flow$Reading)
flow$Date = as.Date(flow$Reading, format="%Y-%m-%d")
View(flow)
library(dplyr)
flow_agg = flow%>%group_by(Date)%>%summarise("mean_daily_cfs"=mean(Reading))
warnings()
str(flow$Reading)
str(flow$Value)
flow_agg = flow%>%group_by(Date)%>%summarise("mean_daily_cfs"=mean(Value))
View(flow_agg)
flow_agg = flow%>%filter(Value>0)%>%group_by(Date)%>%summarise("mean_daily_cfs"=mean(Value))
View(flow_agg)
View(dat)
write.csv(flow_agg, "flow_aggregated.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
file_path = "em_creek_flow.csv"
au_name = "Emigration"
aggFun ="gmean" # geometric mean
correction_factor = 24465715 # correction factor for E. coli
margin_of_safety = 0.1 # percentage
rec_season=c(121,304) # days of the year
irrigation_season=c(135,288) # days of the year
site_order = data.frame(MonitoringLocationIdentifier = c(
"BR_12.29",
"BR_14.15",
"BR_14.44",
"EM_01.62",
"EM_02.54",
"EM_03.67",
"EM_04.17",
"EM_05.17",
"EM_07.30",
"EM_07.79",
"EM_08.50",
"EM_08.83",
"EM_08.93",
"EM_09.48",
"EM_10.43",
"EM_11.87",
"KL_00.21",
"KL_01.50"
),Order = c(1:18))
colorz = c("#f44336",
"#e81e63",
"#9c27b0",
"#673ab7",
"#3f51b5",
"#2196f3",
"#03a9f4",
"#00bcd4",
"#009688",
"#4caf50",
"#8bc34a",
"#cddc39",
"#ffeb3b",
"#ffc107",
"#ff9800",
"#ff5722",
"#795548",
"#9e9e9e",
"#607d8b",
"#000000")
# colorz = c("#034963","#0b86a3","#00a1c6","#cde3e2", "#BFD7B5","#D1CAA1","#D1D2F9","#77625C","#EFA9AE") # these are HEX color codes. Feel free to lengthen, shorten, or change the colors based on your dataset
remove.packages("dwqInsights")
list.of.packages <- c("plyr","dplyr","openxlsx","ggplot2","tidyr","lubridate","plotly","devtools")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
if(!("dwqInsights"%in%installed.packages()[,"Package"])) devtools::install_github("edhinman/dwqInsights")
library(plyr)
library(dplyr)
library(openxlsx)
library(tidyr)
library(lubridate)
library(plotly)
library(dwqInsights)
colorsy=colorz[1:nrow(site_order)]
file_path = "em_creek_flow.csv"
au_name = "Emigration"
aggFun ="gmean" # geometric mean
correction_factor = 24465715 # correction factor for E. coli
margin_of_safety = 0.1 # percentage
rec_season=c(121,304) # days of the year
irrigation_season=c(135,288) # days of the year
site_order = data.frame(MonitoringLocationIdentifier = c(
"BR_12.29",
"BR_14.15",
"BR_14.44",
"EM_01.62",
"EM_02.54",
"EM_03.67",
"EM_04.17",
"EM_05.17",
"EM_07.30",
"EM_07.79",
"EM_08.50",
"EM_08.83",
"EM_08.93",
"EM_09.48",
"EM_10.43",
"EM_11.87",
"KL_00.21",
"KL_01.50"
),Order = c(1:18))
colorz = c("#f44336",
"#e81e63",
"#9c27b0",
"#673ab7",
"#3f51b5",
"#2196f3",
"#03a9f4",
"#00bcd4",
"#009688",
"#4caf50",
"#8bc34a",
"#cddc39",
"#ffeb3b",
"#ffc107",
"#ff9800",
"#ff5722",
"#795548",
"#9e9e9e",
"#607d8b",
"#000000")
# colorz = c("#034963","#0b86a3","#00a1c6","#cde3e2", "#BFD7B5","#D1CAA1","#D1D2F9","#77625C","#EFA9AE") # these are HEX color codes. Feel free to lengthen, shorten, or change the colors based on your dataset
colorsy=colorz[1:nrow(site_order)]
output = dwqInsights::tmdlCalcs(obj = read.csv(wb_path), aggFun = aggFun, cf = correction_factor, mos = margin_of_safety, rec_ssn = rec_season, irg_ssn = irrigation_season, exportfromfunc = TRUE)
?tmdlCalcs
output = dwqInsights::tmdlCalcs(idata = read.csv(wb_path), aggFun = aggFun, cf = correction_factor, mos = margin_of_safety, rec_ssn = rec_season, irg_ssn = irrigation_season, exportfromfunc = TRUE)
output = dwqInsights::tmdlCalcs(idata = read.csv(file_path), aggFun = aggFun, cf = correction_factor, mos = margin_of_safety, rec_ssn = rec_season, irg_ssn = irrigation_season, exportfromfunc = TRUE)
View(output)
head(output)
gmean = function(x){exp(mean(log(x)))}
dat = output
dat_agg = output%>%group_by(MonitoringLocationIdentifier, CharacteristicName,ResultMeasure.MeasureUnitCode)%>%summarise(daterange = paste0(min(Date)," to ",max(Date)),samplesize=length(DailyResultMeasureValue),minconc = min(DailyResultMeasureValue),arithmean=mean(DailyResultMeasureValue),maxconc = max(DailyResultMeasureValue), perc_exc = sum(Exceeds)/length(Exceeds)*100)
rec_mean = output%>%filter(Rec_Season=="rec")%>%group_by(MonitoringLocationIdentifier, CharacteristicName,ResultMeasure.MeasureUnitCode)%>%summarise(rec_ssn_arithmean=mean(DailyResultMeasureValue),rec_ssn_perc_exc = sum(Exceeds)/length(Exceeds)*100)
dat_agg = merge(dat_agg, rec_mean, all = TRUE)
if(aggFun=="gmean"){
dat_agg_geo = output%>%group_by(MonitoringLocationIdentifier, CharacteristicName, ResultMeasure.MeasureUnitCode)%>%summarise(geomean = gmean(DailyResultMeasureValue))
rec_geo = output%>%filter(Rec_Season=="rec")%>%group_by(MonitoringLocationIdentifier, CharacteristicName, ResultMeasure.MeasureUnitCode)%>%summarise(rec_ssn_geomean=gmean(DailyResultMeasureValue))
dat_agg_geo = merge(dat_agg_geo, rec_geo, all = TRUE)
}
dat_agg = merge(dat_agg, dat_agg_geo, all = TRUE)
if("DailyFlowValue"%in%colnames(output)){
flo_agg = output%>%filter(!is.na(DailyFlowValue))%>%group_by(MonitoringLocationIdentifier, ResultMeasure.MeasureUnitCode)%>%summarise(daterange = paste0(min(Date)," to ",max(Date)),samplesize=length(DailyFlowValue),minconc = min(DailyFlowValue),arithmean=mean(DailyFlowValue),maxconc = max(DailyFlowValue))
dat_agg = plyr::rbind.fill(dat_agg, flo_agg)
dat_agg$CharacteristicName[is.na(dat_agg$CharacteristicName)] = "Flow"
}
write.csv(dat_agg, paste0(au_name,"_summary_table_stats.csv"), row.names = FALSE)
head(dat_agg)
## GGPLOT
sites = site_order[order(site_order$Order),]
sites = as.character(sites$MonitoringLocationIdentifier)
dat = output
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
f = ggplot(dat, aes(x=MonitoringLocationIdentifier,y=DailyResultMeasureValue))+geom_jitter(aes(fill=factor(MonitoringLocationIdentifier)), position=position_jitter(0.1), shape=21, size=2, color="#646464")+scale_fill_manual(values= colorsy)+theme_classic()+labs(x="Monitoring Location ID", y=unique(dat$ResultMeasure.MeasureUnitCode))+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=2.5, shape=23)+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none", axis.text.x=element_text(angle=45, hjust=1)) # NOTE, should adjust numeric criterion line to accommodate variable criteria (e.g. hardness-dependent)
f
ggsave(paste0(au_name,"_downstream_upstream.jpg"),width=6,height=4, units="in", dpi=500)
dat = output
dat = dat[order(dat$Date),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
t = ggplot(dat, aes(Date,DailyResultMeasureValue, fill=as.factor(MonitoringLocationIdentifier)))+scale_x_date(limits=c(min(dat$Date), max(dat$Date)))+geom_point(shape=21,color="#646464", size=2)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Date", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)
t
ggsave(paste0(au_name,"_timeseries.jpg"),width=6,height=24, units="in", dpi=500)
dat = output
dat$month = lubridate::month(dat$Date, label=TRUE)
dat = dat[order(dat$month),]
dat$MonitoringLocationIdentifier = factor(as.character(dat$MonitoringLocationIdentifier), levels = sites)
g = ggplot(dat, aes(month, DailyResultMeasureValue, fill=factor(MonitoringLocationIdentifier)))+geom_blank()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(DailyResultMeasureValue)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+geom_jitter(position=position_jitter(0), size=3, shape=21, color="#646464", alpha=0.65)+facet_wrap(vars(MonitoringLocationIdentifier), scales="free", ncol=1)+theme_classic()+labs(x="Month", y=unique(dat$ResultMeasure.MeasureUnitCode))+geom_hline(yintercept=unique(dat$NumericCriterion), color="#cb181d",size=0.5)+theme(legend.position = "none")+scale_fill_manual(values=colorsy)+stat_summary(fun=gmean, geom="point", fill="#FFB800",color="black", size=3, shape=23)
g
ggsave(paste0(au_name,"_monthly.jpg"),width=6,height=24, units="in", dpi=500)
if("TMDL"%in%colnames(output)){
ldc=output
ldc_month = subset(ldc, !is.na(ldc$Observed_Loading))
ldc_month = ldc_month%>%select(Date,MonitoringLocationIdentifier,TMDL,Observed_Loading)%>%pivot_longer(cols=c(TMDL,Observed_Loading),names_to="Type",values_to="Loading",values_drop_na=TRUE)
ldc_month$Loading_Giga = ldc_month$Loading/1000000000
ldc_month$month = lubridate::month(ldc_month$Date, label=TRUE, abbr=TRUE)
ldc_month1 = ldc_month%>%group_by(MonitoringLocationIdentifier,Type,month)%>%summarise(mean_Load = mean(Loading_Giga))
ldcsites = unique(ldc_month1$MonitoringLocationIdentifier)
for(i in 1:length(ldcsites)){
name = ldcsites[i]
g = ggplot(ldc_month1, aes(x=month, y=mean_Load, fill=Type))+geom_blank()+theme_classic()+geom_rect(aes(xmin=4.5,ymin=0,xmax=10.5,ymax=max(ldc_month1$mean_Load*1.1)), fill="#D3D3D3")+scale_x_discrete(limits=month.abb)+labs(x="Month",y="GigaMPN/day")+geom_col(position="dodge", color="#646464")+scale_fill_manual(values=c("#00a1c6","#034963"),name="",breaks=c("Observed_Loading","TMDL"),labels=c("Observed","TMDL"))+guides(color="none")
g
ggsave(paste0(name,"_monthly_load.jpg"),width=8,height=4, units="in", dpi=500)
}
g
}
if("TMDL"%in%colnames(output)){
ldc = output
ldc$TMDL_giga = ldc$TMDL/1000000000
ldc$Observed_Loading_giga = ldc$Observed_Loading/1000000000
ldc = ldc[order(ldc$Flow_Percentile),]
exceed = subset(ldc, !is.na(ldc$Observed_Loading_giga))
exceed = within(exceed,{
regime=NA
regime[Flow_Percentile<10] = "High \nFlows"
regime[Flow_Percentile>9&Flow_Percentile<40] = "Moist \nConditions"
regime[Flow_Percentile>39&Flow_Percentile<60] = "Mid-Range \nFlows"
regime[Flow_Percentile>59&Flow_Percentile<90] = "Dry \nConditions"
regime[Flow_Percentile>89&Flow_Percentile<101] = "Low \nFlows"
})
exceed = exceed%>%group_by(MonitoringLocationIdentifier, regime)%>%summarise(perc_exceed=round(length(Exceeds[Exceeds==1])/length(Exceeds)*100,digits=0))
exceed = within(exceed,{
place = NA
place[regime=="High \nFlows"] =5
place[regime=="Moist \nConditions"] = 25
place[regime=="Mid-Range \nFlows"]=50
place[regime=="Dry \nConditions"] = 75
place[regime=="Low \nFlows"] = 95
})
exceed$label = paste0(exceed$regime,"\n(",exceed$perc_exceed,"%)")
ldcsites = unique(exceed$MonitoringLocationIdentifier)
for(i in 1:length(ldcsites)){
name = ldcsites[i]
why = max(c(ldc$TMDL_giga,ldc$Observed_Loading_giga), na.rm = TRUE)*0.8
l = ggplot(ldc, aes(x=Flow_Percentile))+geom_blank()+geom_vline(xintercept=c(10,40,60,90),linetype=2)+geom_line(aes(y=TMDL_giga, color="TMDL_giga"),color="#034963",size=1.5)+geom_point(aes(y=Observed_Loading_giga, color="Observed_Loading_giga"),shape=21, color="#464646",fill="#00a1c6",size=3)+theme_classic()+labs(x="Flow Percentile",y="GigaMPN/day")+annotate("text",x=exceed$place,y=why, label=exceed$label)+scale_color_manual(name = "",
values = c( "TMDL_giga" = "#034963", "Observed_Loading_giga" = "#00a1c6"),
labels = c("TMDL", "Observed Loading"))
l
ggsave(paste0(name,"_ldc.jpg"),width=8,height=4, units="in", dpi=500)
}
l
}
View(output)
View(ldc)
View(exceed)
if("TMDL"%in%colnames(output)){
ldc = subset(output, !is.na(output$Flow_Percentile))
ldc$TMDL_giga = ldc$TMDL/1000000000
ldc$Observed_Loading_giga = ldc$Observed_Loading/1000000000
ldc = ldc[order(ldc$Flow_Percentile),]
exceed = subset(ldc, !is.na(ldc$Observed_Loading_giga))
exceed = within(exceed,{
regime=NA
regime[Flow_Percentile<10] = "High \nFlows"
regime[Flow_Percentile>9&Flow_Percentile<40] = "Moist \nConditions"
regime[Flow_Percentile>39&Flow_Percentile<60] = "Mid-Range \nFlows"
regime[Flow_Percentile>59&Flow_Percentile<90] = "Dry \nConditions"
regime[Flow_Percentile>89&Flow_Percentile<101] = "Low \nFlows"
})
exceed = exceed%>%group_by(MonitoringLocationIdentifier, regime)%>%summarise(perc_exceed=round(length(Exceeds[Exceeds==1])/length(Exceeds)*100,digits=0))
exceed = within(exceed,{
place = NA
place[regime=="High \nFlows"] =5
place[regime=="Moist \nConditions"] = 25
place[regime=="Mid-Range \nFlows"]=50
place[regime=="Dry \nConditions"] = 75
place[regime=="Low \nFlows"] = 95
})
exceed$label = paste0(exceed$regime,"\n(",exceed$perc_exceed,"%)")
ldcsites = unique(exceed$MonitoringLocationIdentifier)
for(i in 1:length(ldcsites)){
name = ldcsites[i]
why = max(c(ldc$TMDL_giga,ldc$Observed_Loading_giga), na.rm = TRUE)*0.8
l = ggplot(ldc, aes(x=Flow_Percentile))+geom_blank()+geom_vline(xintercept=c(10,40,60,90),linetype=2)+geom_line(aes(y=TMDL_giga, color="TMDL_giga"),color="#034963",size=1.5)+geom_point(aes(y=Observed_Loading_giga, color="Observed_Loading_giga"),shape=21, color="#464646",fill="#00a1c6",size=3)+theme_classic()+labs(x="Flow Percentile",y="GigaMPN/day")+annotate("text",x=exceed$place,y=why, label=exceed$label)+scale_color_manual(name = "",
values = c( "TMDL_giga" = "#034963", "Observed_Loading_giga" = "#00a1c6"),
labels = c("TMDL", "Observed Loading"))
l
ggsave(paste0(name,"_ldc.jpg"),width=8,height=4, units="in", dpi=500)
}
l
}
flow = read,csv(file_path)
flow = read.csv(file_path)
flow = subset(flow, flow$CharacteristicName=="Flow")
flow = read.csv(file_path)
flow = subset(flow, flow$CharacteristicName=="Flow")
h=ggplot(flow, aes(x=ActivityStartDate,y=ResultMeasureValue))+geom_area(color="#646464",fill="#0b86a3")+labs(x="Date",y="Flow (cfs)")+theme_classic()
h
flow$ActivityStartDate = as.Date(flow$ActivityStartDate, format="%m/%d/%Y")
h=ggplot(flow, aes(x=ActivityStartDate,y=ResultMeasureValue))+geom_area(color="#646464",fill="#0b86a3")+labs(x="Date",y="Flow (cfs)")+theme_classic()
h
ggsave(paste0(au_name,"_flow_ts.jpg"),width=8,height=4, units="in", dpi=500)
shiny::runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
View(ldc_month)
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
runApp('inst/loadFigs')
View(loading)
runApp('inst/loadFigs')
View(calcdat)
rec_ssn=c(121,304)
irg_ssn=c(135,288)
exportfromfunc = FALSE
runApp('inst/loadFigs')
aggFun = aggfun
idata = dat
## Calculation functions needed for plotting and assessment ##
perc.red <- function(x,y){100-x/y*100} # percent reduction equation where x = capacity and y = observed
flow_perc <- function(x){(1-percent_rank(x))*100} # gives each flow measurement a percent rank (what percentage of flows are higher than value?)
if(aggFun=="gmean"){
aggFun = function(x){exp(mean(log(x)))}
}
# Determine calendar season - taken from https://stackoverflow.com/questions/9500114/find-which-season-a-particular-date-belongs-to
getSeason <- function(DATES) {
WS <- as.Date("2012-12-15", format = "%Y-%m-%d") # Winter Solstice
SE <- as.Date("2012-3-15",  format = "%Y-%m-%d") # Spring Equinox
SS <- as.Date("2012-6-15",  format = "%Y-%m-%d") # Summer Solstice
FE <- as.Date("2012-9-15",  format = "%Y-%m-%d") # Fall Equinox
# Convert dates from any year to 2012 dates
d <- as.Date(strftime(DATES, format="2012-%m-%d"))
ifelse (d >= WS | d < SE, "Winter",
ifelse (d >= SE & d < SS, "Spring",
ifelse (d >= SS & d < FE, "Summer", "Fall")))}
param.dat = idata
# Load csv
ds_names = names(param.dat)
req_names = c("MonitoringLocationIdentifier","ActivityStartDate","CharacteristicName","ResultMeasureValue","ResultMeasure.MeasureUnitCode","BeneficialUse","NumericCriterion")
missing = req_names[!req_names%in%ds_names]
if(length(missing)>0){
text = paste(missing,collapse=", ")
stop(paste0(text," column(s) missing from input dataset. Add required column(s) before running."))
}
start = dim(param.dat)[1]
param.dat$Date <- as.Date(param.dat$ActivityStartDate, format="%m/%d/%Y")
param.dat = subset(param.dat, !is.na(as.numeric(param.dat$ResultMeasureValue)))
end = dim(param.dat)[1]
if(!(start==end)){
n = start-end
warning(paste0(n," records removed because result value was non-numeric or NA"))
}
# Show parameters and units to inform user composition of dataset
tbl = unique(param.dat[,c("CharacteristicName","ResultMeasure.MeasureUnitCode")])
tbl$concat = apply(tbl, 1 , paste, collapse = "-" )
# Aggregate to daily values
param.agg = subset(param.dat, !param.dat$CharacteristicName%in%c("Flow"))
param.agg.dv = aggregate(ResultMeasureValue~BeneficialUse+MonitoringLocationIdentifier+Date+CharacteristicName+ResultMeasure.MeasureUnitCode+NumericCriterion, data=param.agg, FUN=aggFun)
names(param.agg.dv)[names(param.agg.dv)=="ResultMeasureValue"] = "DailyResultMeasureValue"
param.agg.dv$Exceeds = ifelse(param.agg.dv$DailyResultMeasureValue>param.agg.dv$NumericCriterion,1,0)
param.agg.dv$Season = getSeason(param.agg.dv$Date)
# Rec season and Irrigation season
param.agg.dv$Rec_Season = ifelse(lubridate::yday(param.agg.dv$Date)>=rec_ssn[1]&lubridate::yday(param.agg.dv$Date)<=rec_ssn[2],"rec","not rec")
param.agg.dv$Irg_Season = ifelse(lubridate::yday(param.agg.dv$Date)>=irg_ssn[1]&lubridate::yday(param.agg.dv$Date)<=irg_ssn[2],"irrigation","not irrigation")
if("Flow"%in%unique(tbl$CharacteristicName)){
flow.agg = subset(param.dat, param.dat$CharacteristicName%in%c("Flow"))
flow.agg = aggregate(ResultMeasureValue~MonitoringLocationIdentifier+Date+ResultMeasure.MeasureUnitCode, data=flow.agg, FUN="mean")
names(flow.agg)[names(flow.agg)=="ResultMeasureValue"] = "DailyFlowValue"
names(flow.agg)[names(flow.agg)=="ResultMeasure.MeasureUnitCode"] = "FlowUnit"
flow.agg$Flow_Percentile = flow_perc(flow.agg$DailyFlowValue)
param.agg.dv = merge(param.agg.dv, flow.agg, all.x = TRUE)
param.agg.dv$Observed_Loading = param.agg.dv$DailyResultMeasureValue*cf*param.agg.dv$DailyFlowValue
param.agg.dv$TMDL = param.agg.dv$NumericCriterion*cf*param.agg.dv$DailyFlowValue*(1-mos)
}
View(param.agg.dv)
param.agg.dv$NumericCriterion
param.agg.dv$NumericCriterion*cf*param.agg.dv$DailyFlowValue*(1-mos)
cf
str(param.agg.dv$NumericCriterion)
param.agg.dv$NumericCriterion = as.numeric(param.agg.dv$NumericCriterion)
param.agg.dv$TMDL = param.agg.dv$NumericCriterion*cf*param.agg.dv$DailyFlowValue*(1-mos)
View(param.agg.dv)
rm(param.agg.dv)
param.agg.dv = merge(param.agg.dv, flow.agg, all.x = TRUE)
# Aggregate to daily values
param.agg = subset(param.dat, !param.dat$CharacteristicName%in%c("Flow"))
param.agg.dv = aggregate(ResultMeasureValue~BeneficialUse+MonitoringLocationIdentifier+Date+CharacteristicName+ResultMeasure.MeasureUnitCode+NumericCriterion, data=param.agg, FUN=aggFun)
names(param.agg.dv)[names(param.agg.dv)=="ResultMeasureValue"] = "DailyResultMeasureValue"
param.agg.dv$Exceeds = ifelse(param.agg.dv$DailyResultMeasureValue>param.agg.dv$NumericCriterion,1,0)
param.agg.dv$Season = getSeason(param.agg.dv$Date)
# Rec season and Irrigation season
param.agg.dv$Rec_Season = ifelse(lubridate::yday(param.agg.dv$Date)>=rec_ssn[1]&lubridate::yday(param.agg.dv$Date)<=rec_ssn[2],"rec","not rec")
param.agg.dv$Irg_Season = ifelse(lubridate::yday(param.agg.dv$Date)>=irg_ssn[1]&lubridate::yday(param.agg.dv$Date)<=irg_ssn[2],"irrigation","not irrigation")
if("Flow"%in%unique(tbl$CharacteristicName)){
flow.agg = subset(param.dat, param.dat$CharacteristicName%in%c("Flow"))
flow.agg = aggregate(ResultMeasureValue~MonitoringLocationIdentifier+Date+ResultMeasure.MeasureUnitCode, data=flow.agg, FUN="mean")
names(flow.agg)[names(flow.agg)=="ResultMeasureValue"] = "DailyFlowValue"
names(flow.agg)[names(flow.agg)=="ResultMeasure.MeasureUnitCode"] = "FlowUnit"
flow.agg$Flow_Percentile = flow_perc(flow.agg$DailyFlowValue)
param.agg.dv = merge(param.agg.dv, flow.agg, all.x = TRUE)
param.agg.dv$Observed_Loading = param.agg.dv$DailyResultMeasureValue*cf*param.agg.dv$DailyFlowValue
param.agg.dv$TMDL = as.numeric(param.agg.dv$NumericCriterion)*cf*param.agg.dv$DailyFlowValue*(1-mos)
}
View(param.agg.dv)
devtools::document()
devtools::document()
remove.packages("dwqInsights")
devtools::install_github("edhinman/dwqInsights")
